{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Building Advance RAG Application using Re-ranking and Evaluation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the environment variables from `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the LLM - Llama-3-8B on Groq.\n",
    "2. Initialize the Qdrant Vector DB\n",
    "3. Initialize the Cohere reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "#Obtain the API keys from the Environment Variables\n",
    "chat_groq_api = os.environ[\"GROQ_API_KEY\"]\n",
    "qdrant_api = os.environ[\"QDRANT_API_KEY\"]\n",
    "qdrant_url = os.environ[\"QDRANT_API_URL\"]\n",
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "\n",
    "# Initialize Groq LLM (Llama3)\n",
    "llm = ChatGroq(\n",
    "    temperature = 0.2,\n",
    "    model_name = \"llama3-8b-8192\",\n",
    "    api_key = chat_groq_api\n",
    ")\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize Qdrant vector store\n",
    "vector_store = Qdrant(\n",
    "    client=QdrantClient(url=qdrant_url, api_key=qdrant_api),\n",
    "    collection_name = \"adv_rag\",\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Cohere ReRanker\n",
    "reranker = CohereRerank(cohere_api_key=cohere_api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Sample Dataset to the Qdrant Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 35 documents to Qdrant collection 'adv_rag'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from transformers import AutoTokenizer\n",
    "from qdrant_client.http import models\n",
    "\n",
    "### Loading the data from JSON\n",
    "with open(\"data.json\",\"r\") as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "### Adding the sample data to the Qdrant DB\n",
    "def add_sample_data_to_qdrant(data, collection_name=\"adv_rag\"):\n",
    "    # Initialize the embedding model\n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Initialize Qdrant client\n",
    "    qdrant_client = QdrantClient(url=qdrant_url, api_key=qdrant_api)\n",
    "    \n",
    "    # Create the collection if it doesn't exist\n",
    "    qdrant_client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    "    )\n",
    "    \n",
    "    # Initialize Qdrant vector store\n",
    "    vector_store = Qdrant(\n",
    "    client=QdrantClient(url=qdrant_url, api_key=qdrant_api),\n",
    "    collection_name =collection_name,\n",
    "    embeddings=embed_model\n",
    "    )\n",
    "    \n",
    "    # Add data to Qdrant\n",
    "    texts = [f\"{item['title']}\\n\\n{item['content']}\" for item in data]\n",
    "    vector_store.add_texts(texts)\n",
    "    \n",
    "    print(f\"Added {len(texts)} documents to Qdrant collection '{collection_name}'\")\n",
    "\n",
    "# Add the sample data to Qdrant\n",
    "add_sample_data_to_qdrant(sample_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Function to Generate Multiple (5 here) queries for a given user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generator_template = \"\"\"\n",
    "Generate 5 different search queries based on the following user question:\n",
    "User question: {question}\n",
    "\n",
    "Output the queries in a numbered list.\n",
    "\"\"\"\n",
    "\n",
    "query_generator_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=query_generator_template\n",
    ")\n",
    "\n",
    "query_generator_chain = LLMChain(llm=llm, prompt=query_generator_prompt)\n",
    "\n",
    "def generate_queries(question):\n",
    "    result = query_generator_chain.invoke({\"question\": question})\n",
    "    queries = [q.strip() for q in result['text'].split(\"\\n\") if q.strip() and q[0].isdigit()]\n",
    "    return queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response Generation with Retrieval and Reranking using Cohere Reranker which performs ranking based on their relevance to the provided query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rerank(query, top_k=5):\n",
    "    base_retriever = vector_store.as_retriever(search_kwargs={\"k\": top_k * 2})\n",
    "    retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=reranker,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "    return retriever.get_relevant_documents(query)\n",
    "\n",
    "response_template = \"\"\"\n",
    "Based on the following context, please answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a detailed and informative answer:\n",
    "\"\"\"\n",
    "\n",
    "response_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=response_template\n",
    ")\n",
    "\n",
    "response_chain = LLMChain(llm=llm, prompt=response_prompt)\n",
    "\n",
    "def generate_response(question, context):\n",
    "    return response_chain.invoke({\"question\": question, \"context\": context})['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the responses based on Relevance, Accuracy and Completeness using the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_template = \"\"\"\n",
    "Evaluate the following response to the given question based on relevance, accuracy, and completeness.\n",
    "Provide a score from 1 to 10 for each criterion, where 1 is the lowest and 10 is the highest.\n",
    "\n",
    "Question: {question}\n",
    "Response: {response}\n",
    "\n",
    "Evaluation:\n",
    "1. Relevance (1-10):\n",
    "2. Accuracy (1-10):\n",
    "3. Completeness (1-10):\n",
    "\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"response\"],\n",
    "    template=evaluation_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=llm, prompt=evaluation_prompt)\n",
    "\n",
    "def evaluate_response(question, response):\n",
    "    return evaluation_chain.invoke({\"question\": question, \"response\": response})['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire RAG Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cohere\n",
    "\n",
    "co = cohere.Client(cohere_api_key)\n",
    "\n",
    "def rerank_responses(evaluated_responses,user_question):\n",
    "        reranked_responses = []\n",
    "        for response_set in evaluated_responses:\n",
    "            rerank = co.rerank(\n",
    "                model = 'rerank-english-v1.0',\n",
    "                query = user_question,\n",
    "                documents=response_set[1],\n",
    "                top_n = 1\n",
    "            )\n",
    "            reranked_responses.append(rerank)\n",
    "        return reranked_responses\n",
    "def parse_evaluation_score(evaluation):\n",
    "    scores = re.findall(r'\\d+', evaluation)\n",
    "    return sum(map(int, scores)) / len(scores) if scores else 0\n",
    "\n",
    "# Entire Pipeline for Adv RAG\n",
    "def advanced_rag(user_question, num_responses=3):\n",
    "    # Generate multiple queries\n",
    "    queries = generate_queries(user_question)\n",
    "    \n",
    "    # Obtaining the documents through retrieval and reranking\n",
    "    all_documents = []\n",
    "    for query in queries:\n",
    "        print(\"Generated Query : \",query)\n",
    "        # Retrieve and rerank documents for each query\n",
    "        documents = retrieve_and_rerank(query,top_k=5)\n",
    "        all_documents.extend(documents)\n",
    "    \n",
    "    # Remove duplicates and get the top 5 unique documents\n",
    "    unique_documents = list({doc.page_content: doc for doc in all_documents}.values())[:5]\n",
    "    \n",
    "    # Generate multiple responses\n",
    "    responses = []\n",
    "    for i in range(num_responses):\n",
    "        context = \"\\n\".join([doc.page_content for doc in unique_documents])\n",
    "        response = generate_response(user_question, context)\n",
    "        responses.append(response)\n",
    "    \n",
    "    # Evaluate responses\n",
    "    evaluated_responses = []\n",
    "    for response in responses:\n",
    "        evaluation = evaluate_response(user_question, response)\n",
    "        evaluated_responses.append((response, evaluation))\n",
    "    \n",
    "    #########################################################################################\n",
    "    # If you have premium access to Cohere API, you can try to Rank the Evaluated outputs too\n",
    "    # Since I use a trial version, it only allows 10 API calls/min. \n",
    "    # Please enable the below code in case you want to rerank the evaluated output\n",
    "    '''\n",
    "    final_responses = rerank_responses(evaluated_responses,user_question)\n",
    "    print(\"Ranked Responses : \",final_responses)\n",
    "    '''    \n",
    "    #########################################################################################\n",
    "\n",
    "    # Sort responses by evaluation score\n",
    "    sorted_responses = sorted(evaluated_responses, key=lambda x: parse_evaluation_score(x[1]), reverse=True)\n",
    "    \n",
    "\n",
    "    return sorted_responses[0][0]  # Return the highest-rated response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER QUERY: What are the main challenges in implementing quantum computing?\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Query :  1. \"Challenges of implementing quantum computing\"\n",
      "Generated Query :  2. \"Barriers to quantum computing adoption\"\n",
      "Generated Query :  3. \"Quantum computing implementation difficulties\"\n",
      "Generated Query :  4. \"Obstacles to scaling up quantum computing\"\n",
      "Generated Query :  5. \"Quantum computing integration challenges\"\n",
      "\n",
      "\n",
      "\n",
      "User Question: What are the main challenges in implementing quantum computing?\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "Best Response after Retrieval, Reranking and Evaluation: \n",
      "\n",
      "According to the provided context, the main challenges in implementing quantum computing are:\n",
      "\n",
      "1. **Maintaining Quantum Coherence**: Qubits are extremely sensitive to environmental disturbances, making it difficult to maintain their quantum state. This is a significant hurdle in building reliable quantum computers.\n",
      "\n",
      "2. **Error Correction**: Quantum states are inherently prone to errors, which can be caused by decoherence, noise, and other factors. Developing effective error correction techniques is crucial to ensure the accuracy and reliability of quantum computations.\n",
      "\n",
      "3. **Scalability**: Building practical quantum computers that can scale up to solve complex problems is a significant challenge. As the number of qubits increases, the complexity of maintaining quantum coherence and correcting errors also grows.\n",
      "\n",
      "These challenges are significant obstacles to overcome before quantum computers can realize their full potential. However, researchers are actively working to develop innovative solutions to address these challenges, which could lead to breakthroughs in various fields and applications.\n"
     ]
    }
   ],
   "source": [
    "# Sample User Query\n",
    "user_question = \"What are the main challenges in implementing quantum computing?\"\n",
    "print(f\"USER QUERY: {user_question}\")\n",
    "print(f\"{'-'*(20+len(user_question))}\\n\")\n",
    "\n",
    "best_response = advanced_rag(user_question,num_responses=3)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"User Question: {user_question}\")\n",
    "print(f\"{'-'*(20+len(user_question))}\\n\")\n",
    "print(f\"Best Response after Retrieval, Reranking and Evaluation: \\n\\n{best_response}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39ca01f20b84907b60a40c476d4d070ed5f120d70a144b3c9cb1a6cd31f26857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
